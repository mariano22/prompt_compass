{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d11679e0-cb1c-4707-a406-9b553eace77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "from predictors import *\n",
    "from llm import *\n",
    "from prompts import *\n",
    "from tools import *\n",
    "\n",
    "BIG_MODEL = \"gpt-4.1\"\n",
    "MEDIUM_MODEL = \"gpt-4.1-mini\"\n",
    "SMALL_MODEL = \"gpt-4.1-nano\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee73d920-304a-4bdb-9c3e-c42d4aa5257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "training, validation = build_datasets(dataset, 1000, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3231f07-3f66-4921-8daa-6ae849ff387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an expert at solving math word problems. \n",
      "Given a math question, provide a step-by-step method to solve this type of problem without being too specific to the problem itself.\n",
      "\n",
      "Your instructions will be provided to a LLM student agent who will follow the method you create on a slightly different problem.\n",
      "You can assume that we will only change the quantities and the name of the people.\n",
      "\n",
      "Finally, solve the problem using your method so I can include an example of applying the technique.\n",
      "\n",
      "\n",
      "<problem>\n",
      "    <question>\n",
      "        Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "    </question>\n",
      "    \n",
      "    <thoughts>\n",
      "        Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "    </thoughts>\n",
      "    \n",
      "    <answer>\n",
      "        72\n",
      "    </answer>\n",
      "</problem>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case_prompt = \"\"\"\n",
    "<problem>\n",
    "    <question>\n",
    "        {question}\n",
    "    </question>\n",
    "    \n",
    "    <thoughts>\n",
    "        {thoughts}\n",
    "    </thoughts>\n",
    "    \n",
    "    <answer>\n",
    "        {answer}\n",
    "    </answer>\n",
    "</problem>\n",
    "\"\"\"\n",
    "def make_prompt_case(case):\n",
    "    keys = [k[1] for k in string.Formatter().parse(case_prompt) if k[1]]\n",
    "    return case_prompt.format(**{k:case[k] for k in keys})\n",
    "\n",
    "teacher_template = \"\"\"\n",
    "You are an expert at solving math word problems. \n",
    "Given a math question, provide a step-by-step method to solve this type of problem without being too specific to the problem itself.\n",
    "\n",
    "Your instructions will be provided to a LLM student agent who will follow the method you create on a slightly different problem.\n",
    "You can assume that we will only change the quantities and the name of the people.\n",
    "\n",
    "Finally, solve the problem using your method so I can include an example of applying the technique.\n",
    "\n",
    "{problem}\n",
    "\"\"\"\n",
    "\n",
    "def make_prompt_teacher(case):\n",
    "    return teacher_template.format(problem=make_prompt_case(case))\n",
    "\n",
    "print(make_prompt_teacher(training[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20440ba7-05f5-40d3-823a-063a8bf71309",
   "metadata": {},
   "source": [
    "You are an expert at solving math word problems. \n",
    "\n",
    "<problem> \n",
    "\n",
    "    <question> \n",
    "    Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips   did Natalia sell altogether in April and May? \n",
    "    </question> \n",
    "\n",
    "</problem> \n",
    "1. The goal is to identify the relevant quantities of the problem. We don't need to calculate them now.\n",
    "1.a. Rewrite the statement, thinking step-by-step about which quantities are relevant.\n",
    "1.b. Give a list [(description: str, quantity_name: str)] with the description of the quantity and the quantity name (a variable name using snake case). \n",
    "2. The goal is to identify the functional relationship as equations between the quantities.\n",
    "2.a.  Rewrite the pieces of text that express a relationship between two or more quantities.\n",
    "2.b. For each relationship, write a math equation between the respective variable names of the quantities defined in (1.b)\n",
    "3. The goal is to identify the constants in the statement and their relationship with the quantities.\n",
    "3.a. Rewrite the pieces of text where any constant appears.\n",
    "3.b. For each constant, write math equations between it and the quantities. Use the quantity names defined in (1.b)\n",
    "4. The goal is to parse the last trace of messages and sum-up everything in one JSON output with the following format:\n",
    "{\n",
    "'quantities': [ name_of_quantity: str ]\n",
    "'equations': [ math_equation: str ]\n",
    "''\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519fb6d-176c-40e8-9fd6-6206b3b6c6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54fc495-4247-4f6d-9bf1-7aca7c156afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23acabc7-dcc5-4f9d-a8af-7bc40fe6f0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea76a8d9-8a0d-4716-b2b9-4d25aa01b7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '\\n• Introduce a mandatory multi‑step framework:  (A) Re‑state & label data  (B) Plan  (C) Execute line‑by‑line arithmetic  (D) Sanity‑check  (E) Produce answer.\\n• Make the JSON schema strict: \"thoughts\" must show the full working, \"answer\" a bare number.\\n• Warn that describing operations in words without the accompanying arithmetic is incorrect and will be graded as failure.\\n• Give two miniature examples: one correct (with explicit numbers) and one incorrect (only narrative) so the agent sees the difference.\\n• Remind the agent to watch for off‑by‑one, fraction, unit‑conversion and conditional‑logic traps.\\n• Encourage plugging the result back into the original context as a quick validation step.\\nThese measures force the agent to surface each inference, dramatically lowering careless arithmetic or logic slips.\\n==========\\nYou are a meticulous solver of math word problems.\\nFollow ALL the steps below BEFORE writing the final answer.\\n——————————————————————————\\nSTEP 1  Extract Data\\n • Copy every given number, unit and key condition from the problem into a bulleted list.\\nSTEP 2  Set Up\\n • Define variables if needed.\\n • Translate the conditions into algebraic equations or arithmetic plans.\\nSTEP 3  Compute Explicitly (MANDATORY)\\n • Perform every arithmetic operation on its own line, in the form  expression = value.\\n • Keep units visible until the very last numeric stage.\\nSTEP 4  Convert / Adjust\\n • Convert units (minutes→hours, etc.) or apply inclusive/exclusive counting where relevant.\\nSTEP 5  Sanity Check\\n • Plug the result back into the story or estimate the order of magnitude.  If something is inconsistent, STOP and fix it.\\nSTEP 6  Produce Output\\nReturn only the following JSON structure (no additional keys, no prose outside JSON):\\n{\\n  \"thoughts\": \"<your step‑by‑step work and the sanity check>\",\\n  \"value\": <final number>\\n}\\n\\n——————————————————————————\\nEXAMPLE OF REQUIRED STYLE\\nProblem (abridged):  “A pool holds 7000 L. It is ¾ full. How many litres of water are in it?”\\nOutput →\\n{\\n  \"thoughts\": \"Capacity = 7000 L\\nFraction full = 3/4\\nWater = 3/4 * 7000 = 5250 L\\nSanity‑check: ¾ of 7000 is slightly more than half, 5250 OK\",\\n  \"value\": 5250\\n}\\n\\nINCORRECT STYLE (will be graded wrong)\\n\"Calculate three quarters of 7000 to find the answer.\"\\n——————————————————————————\\nRemember: no skipped arithmetic, no hidden reasoning, no extra keys.\\n\\n<question>\\nHow much is 2+2?\\n</question>\\n',\n",
       " 'response': '{\"thoughts\":\"STEP 1 Extract Data\\\\n• Number 1 = 2\\\\n• Number 2 = 2\\\\nSTEP 2 Set Up\\\\n• Let sum = Number 1 + Number 2\\\\nSTEP 3 Compute Explicitly (MANDATORY)\\\\n2 + 2 = 4\\\\nSTEP 4 Convert / Adjust\\\\n• No unit conversion needed\\\\nSTEP 5 Sanity Check\\\\n• 2 plus 2 is 4, which matches basic arithmetic\\\\nSTEP 6 Produce Output\",\"value\":4}',\n",
       " 'predicted': 4,\n",
       " 'predicted_thoughts': 'STEP 1 Extract Data\\n• Number 1 = 2\\n• Number 2 = 2\\nSTEP 2 Set Up\\n• Let sum = Number 1 + Number 2\\nSTEP 3 Compute Explicitly (MANDATORY)\\n2 + 2 = 4\\nSTEP 4 Convert / Adjust\\n• No unit conversion needed\\nSTEP 5 Sanity Check\\n• 2 plus 2 is 4, which matches basic arithmetic\\nSTEP 6 Produce Output',\n",
       " 'model': 'gpt-4.1'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = await predict_cot(\"How much is 2+2?\", model=BIG_MODEL)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80bdc9e-6e47-4359-b8ce-90828008ca86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afcf706-2fc3-4a99-ac88-182755a411c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate(test_set, predict_fn, tag, max_concurrent_requests: int = 10):\n",
    "    semaphore = asyncio.Semaphore(max_concurrent_requests)\n",
    "    async def evaluate_item(item):\n",
    "         async with semaphore:\n",
    "             result = await predict_fn(item[\"question\"])\n",
    "             return evaluate_item_result(item, result)\n",
    "    tasks = [evaluate_item(item) for item in test_set]\n",
    "    results = []\n",
    "    for f in tqdm_asyncio.as_completed(tasks):\n",
    "        result = await f\n",
    "        results.append(result)\n",
    "    return {\n",
    "        'tag': tag,\n",
    "        'results': results,\n",
    "    } \n",
    "\n",
    "\n",
    "\n",
    "model = SMALL_MODEL\n",
    "fn_name = 'predict_cot'\n",
    "predict_fn = partial(eval(fn_name), model=model)\n",
    "tag = fn_name + '-' + model\n",
    "\n",
    "results_examples = await evaluate(validation[:3], predict_fn, tag, max_concurrent_requests=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74cbc14b-7d4c-4d26-ad56-53093cc49212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 300/300 [00:57<00:00,  5.23it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6602ff2-98ca-4d7c-b4f0-f054c35689ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thoughts', 'plan', 'execute', 'sanity_check', 'produce']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z={'thoughts': 'Step 1: Extract Data\\n- Total days in April = 30\\n- Sundays in April = 4\\n- Total days John walks the dog = 30 - 4 = 26\\n- Cost per day for walking the dog = $10\\n- Total money spent on dog walking = 26 * 10 = $260\\n- Money spent on books = $50\\n- Money given to Kaylee = $50\\n- Total money spent on books and Kaylee = 50 + 50 = $100\\n- Total money spent = 260 + 100 = $360\\nSanity check: John spends $360, so initial money must be at least $360 to have any left.', 'plan': 'Calculate total expenditure and subtract from initial amount to find remaining money.', 'execute': 'Total dog walking cost = 26 * 10 = $260\\nTotal spent on books and giving to Kaylee = 50 + 50 = $100\\nTotal expenditure = 260 + 100 = $360\\nRemaining money = initial amount - total expenditure\\nSince the initial amount is not given, assume initial amount = x\\nRemaining money = x - 360', 'sanity_check': \"The total expenditure is $360. The remaining money depends on John's initial amount. Without initial amount, we cannot compute the exact remaining money.\", 'produce': 'The remaining money is initial amount minus $360.'}\n",
    "list(z.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ed09d6-3d3a-4b79-bfcb-34648134dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"results_examples_cot_small_model.pkl\", \"rb\") as f:\n",
    "    results_examples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6bc89d5-dc61-4d24-9fc1-75469ec2ad44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pass_rate': 88.66666666666667,\n",
       " 'format_error_rate': 1.0,\n",
       " 'api_error_rate': 0.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_pass_rate(results):\n",
    "    total = len(results)\n",
    "    passed = sum(1 for result in results if result[\"pass\"])\n",
    "    format_error = sum(1 for result in results if result[\"format_error\"])\n",
    "    api_error = sum(1 for result in results if result[\"api_error\"])\n",
    "    return {\n",
    "        'pass_rate': (passed / total) * 100,\n",
    "        'format_error_rate': (format_error / total) * 100,\n",
    "        'api_error_rate': (api_error / total) * 100,\n",
    "    }\n",
    "calculate_pass_rate(results_examples['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88bb4d4a-27a7-4be4-bebf-8bc023423756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Assuming results_examples is already defined\n",
    "with open(\"results_examples_cot_small_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results_examples, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03046c-ab6b-4367-bb3b-d33327152dfd",
   "metadata": {},
   "source": [
    "BIG_MODEL naive\n",
    "\n",
    "{'pass_rate': 59.333333333333336,\n",
    " 'format_error_rate': 2.3333333333333335,\n",
    " 'api_error_rate': 0.0}\n",
    "\n",
    "BIG_MODEL CoT\n",
    "\n",
    "{'pass_rate': 88.0, 'format_error_rate': 0.0, 'api_error_rate': 0.0}\n",
    "\n",
    "{'pass_rate': 94.0,\n",
    " 'format_error_rate': 0.0,\n",
    " 'api_error_rate': 0.33333333333333337}\n",
    "\n",
    "\n",
    "BIG_MODEL CoT fixed examples\n",
    "\n",
    "{'pass_rate': 95.33333333333334, 'format_error_rate': 0.0, 'api_error_rate': 0.33333333333333337}\n",
    "\n",
    "NANO naive\n",
    "\n",
    "{'pass_rate': 27.0, 'format_error_rate': 6.0, 'api_error_rate': 0.0}\n",
    "\n",
    "NANO CoT\n",
    "\n",
    "{'pass_rate': 66.33333333333333, 'format_error_rate': 0.0, 'api_error_rate': 1.0}\n",
    "{'pass_rate': 67.33333333333333, 'format_error_rate': 0.0, 'api_error_rate': 0.6666666666666667}\n",
    "{'pass_rate': 66.66666666666666, 'format_error_rate': 0.0, 'api_error_rate': 0.0}\n",
    "\n",
    "NANO CoT (improved by meta-prompting 1 iteration using BIG_MODEL)\n",
    "{'pass_rate': 84.33333333333334, 'format_error_rate': 0.0,'api_error_rate': 0.0}\n",
    "NANO CoT (improved by meta-prompting 2 iteration using BIG_MODEL)\n",
    "(similar result as before)\n",
    "\n",
    "NANO CoT (improved by meta-prompting 1 iteration using o3 reasoning)\n",
    "{'pass_rate': 88.66666666666667, 'format_error_rate': 1.0, 'api_error_rate': 0.0}\n",
    "\n",
    "NANO CoT fixed examples\n",
    "3 examples\n",
    "{'pass_rate': 76.66666666666667, 'format_error_rate': 0.0, 'api_error_rate': 1.3333333333333335}\n",
    "6 examples\n",
    "{'pass_rate': 89.0, 'format_error_rate': 0.0, 'api_error_rate': 0.0}\n",
    "12 examples\n",
    "{'pass_rate': 82.0, 'format_error_rate': 0.0, 'api_error_rate': 0.0}\n",
    "\n",
    "NANO CoT learned examples\n",
    "3 examples\n",
    "{'pass_rate': 77.0, 'format_error_rate': 0.0, 'api_error_rate': 0.0}\n",
    "6 examples\n",
    "{'pass_rate': 89.0, 'format_error_rate': 0.0, 'api_error_rate': 0.0}\n",
    "12 examples\n",
    "\n",
    "50 examples\n",
    "\n",
    "100 examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c489e3f6-61b5-4dc6-acb3-f539e8ce4f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%a{\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"\"\"\n",
    "%%a{{\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a00b37f-38bd-4ae8-af0c-f6827c3952e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMMY_PROMPT = \"Explain quantum entanglement in simple terms, using metaphors and examples. Make the explanation about 2000 words long.\"\n",
    "import time\n",
    "import tiktoken\n",
    "from openai import OpenAI\n",
    "\n",
    "# Create sync client\n",
    "client = OpenAI()\n",
    "# Tokenizer setup\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def measure_speed(client: OpenAI, model_name: str):\n",
    "    messages = [{\"role\": \"user\", \"content\": DUMMY_PROMPT}]\n",
    "    \n",
    "    start = time.monotonic()\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    end = time.monotonic()\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "    output_tokens = count_tokens(content)\n",
    "    elapsed = end - start\n",
    "    speed = output_tokens / elapsed\n",
    "\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"output_tokens\": output_tokens,\n",
    "        \"elapsed_sec\": elapsed,\n",
    "        \"speed_tokens_per_sec\": speed,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be08ac30-83aa-4f36-9ed0-bd4049190e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark():\n",
    "    models = [\"gpt-4.1\", \"gpt-4.1-mini\", \"gpt-4.1-nano\"]\n",
    "    results = []\n",
    "\n",
    "    for model in models:\n",
    "        print(f\"Benchmarking {model}...\")\n",
    "        result = measure_speed(client, model)\n",
    "        print(f\"Model: {result['model']}\")\n",
    "        print(f\"Output Tokens: {result['output_tokens']}\")\n",
    "        print(f\"Elapsed Time: {result['elapsed_sec']:.2f} sec\")\n",
    "        print(f\"Speed: {result['speed_tokens_per_sec']:.2f} tokens/sec\\n\")\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69e25852-6e7a-479f-9775-68cf219271ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking gpt-4.1...\n",
      "Model: gpt-4.1\n",
      "Output Tokens: 2635\n",
      "Elapsed Time: 58.71 sec\n",
      "Speed: 44.88 tokens/sec\n",
      "\n",
      "Benchmarking gpt-4.1-mini...\n",
      "Model: gpt-4.1-mini\n",
      "Output Tokens: 1642\n",
      "Elapsed Time: 17.53 sec\n",
      "Speed: 93.67 tokens/sec\n",
      "\n",
      "Benchmarking gpt-4.1-nano...\n",
      "Model: gpt-4.1-nano\n",
      "Output Tokens: 2102\n",
      "Elapsed Time: 9.23 sec\n",
      "Speed: 227.68 tokens/sec\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': 'gpt-4.1',\n",
       "  'output_tokens': 2635,\n",
       "  'elapsed_sec': 58.7119711250125,\n",
       "  'speed_tokens_per_sec': 44.88011472804115},\n",
       " {'model': 'gpt-4.1-mini',\n",
       "  'output_tokens': 1642,\n",
       "  'elapsed_sec': 17.52961220900761,\n",
       "  'speed_tokens_per_sec': 93.6700698465113},\n",
       " {'model': 'gpt-4.1-nano',\n",
       "  'output_tokens': 2102,\n",
       "  'elapsed_sec': 9.232372332990053,\n",
       "  'speed_tokens_per_sec': 227.67712611512857}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = run_benchmark()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd4afcb8-4d7f-4c6b-a578-3c26d89065ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47912972416463606, 0.4114162517983714)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=res[0]['speed_tokens_per_sec']\n",
    "m=res[1]['speed_tokens_per_sec']\n",
    "s=res[2]['speed_tokens_per_sec']\n",
    "b/m,m/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b79d95-d4fb-4217-bbf3-3ce09421897f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
